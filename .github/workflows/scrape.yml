```yaml
     name: Auto-Scrape Awesome Lists

     on:
       schedule:
         - cron: '0 0 * * *'  # Runs daily at midnight UTC
       workflow_dispatch:  # Allows manual trigger

     jobs:
       scrape:
         runs-on: ubuntu-latest
         steps:
           - name: Checkout repo
             uses: actions/checkout@v4
             with:
               fetch-depth: 0  # Full history
               ref: master  # Use master branch

           - name: Set up Python
             uses: actions/setup-python@v5
             with:
               python-version: '3.9'

           - name: Install dependencies
             run: |
               python -m pip install --upgrade pip
               pip install scrapy frontmatter lxml

           - name: Debug file structure before scrape
             run: |
               ls -R
               echo "Checking awesome.txt:"
               cat extension/data/awesome.txt || echo "File not found or empty"

           - name: Run scraper to update data
             run: python scraper/awesome_scraper.py
             env:
               GH_TOKEN: ${{ secrets.GH_TOKEN }}  # Use GH_TOKEN for custom secret, or remove if using built-in GITHUB_TOKEN

           - name: Debug file structure after scrape
             run: |
               ls -R
               echo "Checking awesome.txt after scrape:"
               cat extension/data/awesome.txt || echo "File not found or empty"
               echo "Checking data_summary.json:"
               cat extension/data_summary.json || echo "File not found or empty"

           - name: Commit and push updated data
             run: |
               git config user.name "Automated Scraper"
               git config user.email "actions@github.com"
               git add extension/data/awesome.txt || echo "No awesome.txt to add"
               git add extension/data/urls/awesome/ || echo "No urls/awesome files to add"
               git commit -m "Auto-update scraped content: $(date -u)" || echo "No changes to commit"
               git push
     ```
